{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719829e6-2ab6-4a71-ae66-2badd05a7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.formula.api import logit\n",
    "from statsmodels.api import Logit\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe30fd-514e-4265-bf1d-3ba3d3fe19b0",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let us recall from previous lecture that regression tasks are special examples of supervised learning algorithms where the independent variables and dependent variables are both numerical and the model has the shape\n",
    "\n",
    "$$ y_i \\approx \\beta x_i + \\alpha + \\epsilon $$\n",
    "\n",
    "where $\\alpha$ and $\\beta$ are constants to be determined and $\\epsilon \\sim N(0,\\sigma)$.\n",
    "\n",
    "There are, however, some assumptions that we do not mention often:\n",
    "\n",
    "1. $x_i$'s are real random vectors.\n",
    "2. $y_i$'s are real numbers that can be both negative and positive.\n",
    "\n",
    "But what happens if we relax the second condition. One such common case is when $y_i$'s are not real random variable but binary categorical variable such as YES or NO.\n",
    "\n",
    "\n",
    "## Underlying assumption\n",
    "\n",
    "Assume we have a collection of data points $(x_i,y_i)$ where $x_i\\in\\mathbb{R}^n$ and $y_i\\in\\{0,1\\}$. Now, assume that there is a hyper-plane $P$ that separates points $x_i$ whose $y_i=0$, and points $x_i$ whose $y_i=1$. Any such hyper-plane $P$ has the equation $ n\\cdot \\mathbf{x} + b = 0 $ where $n$ is the normal vector of the hyper-plane and $b$ is the displacement.\n",
    "\n",
    "\n",
    "> Question: We know that such hyper-planes divide $\\mathbb{R}^n$ into 2 pieces. Given a point $\\mathbf{x}$ in $\\mathbb{R}^n$, how can we figure out which side of the hyperplane $P$ it resides?\n",
    "\n",
    "\n",
    "## The logistic function\n",
    "\n",
    "We need a function that exaggerate negative and positive values. Something that converges to 0 fast the negative $x$-axis, and something that converges to 1 fast on the positive $x$-axis. [The logistic function]() does exactly that\n",
    "\n",
    "$$ \\sigma(x) = \\frac{e^x}{1+e^x} = \\frac{1}{1+e^{-x}} $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc89f18-aa8f-4879-a29e-7928afa2dd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8cfc678550>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.linspace(-10,10,50)\n",
    "ys = 1/(1+np.exp(-xs))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(xs,ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb5115-7ee1-42fa-aa76-87bb851f90ba",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Let us say that the probability of a point ${\\mathbf x}$ being on the positive side of the hyper-plane ${\\mathbf n}\\cdot {\\mathbf x}+b=0$ is \n",
    "\n",
    "$$\\frac{1}{1+e^{-{\\mathbf n}\\cdot {\\mathbf x} - b}}$$\n",
    "\n",
    "Using this we can write a probability function $p({\\mathbf x},y)$ that a point ${\\mathbf x}$ having $y$ as the response as follows:\n",
    "\n",
    "$$p({\\mathbf x},y) = \\left(\\frac{1}{1+e^{-{\\mathbf n}\\cdot {\\mathbf x} - b}}\\right)^y \\left(\\frac{1}{1+e^{{\\mathbf n}\\cdot {\\mathbf x} + b}}\\right)^{1-y} $$\n",
    "which measures the probability of ${\\mathbf x}$ being on the right side where $y$ takes values 0 or 1.  Then the probability that all of the points in our dataset being on the right side is \n",
    "\n",
    "$$ p(D) = \\prod_{i=1}^n p(x_i,y_i) $$ \n",
    "\n",
    "and therefore we would like to maximize $p(D)$ depending on the unknown parameters ${\\mathbf n}\\in\\mathbb{R}^n$ and $b$. Instead one can minimize the following function \n",
    "\n",
    "$$ LE({\\mathbf n},b) = -\\frac{1}{n}\\sum_{i=1}^n y_i\\log(1+e^{-{\\mathbf n}\\cdot x_i - b}) + (1-y_i)\\log(1+e^{{\\mathbf n}\\cdot x_i + b}) $$ \n",
    "\n",
    "which is just the natural logarithm of $p(D)$. Then the best-fitting ${\\mathbf n}$ and $b$ is given by \n",
    "\n",
    "$$ \\text{argmin}_{{\\mathbf n,b}} LE({\\mathbf n},b) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd03f745-653c-4f6d-a102-4b3b1e363903",
   "metadata": {},
   "source": [
    "## An Example\n",
    "\n",
    "Here is a simple example. We are going to consider the [Iris Dataset](https://archive.ics.uci.edu/ml/datasets/iris):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62feb16-3b37-4194-91eb-3ea7fc70bbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       a    b    c    d               p\n",
       "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "iris.columns = ['a','b','c','d','p']\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "361463c1-6aed-483e-ba63-8e42f684efa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.039662\n",
      "         Iterations 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>p3</td>        <th>  No. Observations:  </th>  <td>   150</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   145</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 24 Oct 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.9377</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>13:39:13</td>     <th>  Log-Likelihood:    </th> <td> -5.9493</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -95.477</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.189e-37</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -42.6378</td> <td>   25.708</td> <td>   -1.659</td> <td> 0.097</td> <td>  -93.024</td> <td>    7.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>a</th>         <td>   -2.4652</td> <td>    2.394</td> <td>   -1.030</td> <td> 0.303</td> <td>   -7.158</td> <td>    2.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b</th>         <td>   -6.6809</td> <td>    4.480</td> <td>   -1.491</td> <td> 0.136</td> <td>  -15.461</td> <td>    2.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>c</th>         <td>    9.4294</td> <td>    4.737</td> <td>    1.990</td> <td> 0.047</td> <td>    0.145</td> <td>   18.714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d</th>         <td>   18.2861</td> <td>    9.743</td> <td>    1.877</td> <td> 0.061</td> <td>   -0.809</td> <td>   37.381</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.73 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                     p3   No. Observations:                  150\n",
       "Model:                          Logit   Df Residuals:                      145\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Mon, 24 Oct 2022   Pseudo R-squ.:                  0.9377\n",
       "Time:                        13:39:13   Log-Likelihood:                -5.9493\n",
       "converged:                       True   LL-Null:                       -95.477\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.189e-37\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -42.6378     25.708     -1.659      0.097     -93.024       7.748\n",
       "a             -2.4652      2.394     -1.030      0.303      -7.158       2.228\n",
       "b             -6.6809      4.480     -1.491      0.136     -15.461       2.099\n",
       "c              9.4294      4.737      1.990      0.047       0.145      18.714\n",
       "d             18.2861      9.743      1.877      0.061      -0.809      37.381\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.73 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris.iloc[:,:4]\n",
    "y = iris.iloc[:,4]\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "yy = encoder.fit_transform(np.array(y).reshape(-1,1))\n",
    "\n",
    "res = pd.concat([X,pd.DataFrame(yy)],axis=1)\n",
    "res.columns = ['a','b','c','d','p1','p2','p3']\n",
    "res\n",
    "\n",
    "model = logit('p3 ~ a + b + c + d', data=res).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1fd46bc-d1c3-4115-9ea4-0684f0f3fa24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "model1 = LogisticRegression(max_iter=1500)\n",
    "model1.fit(X_train,y_train)\n",
    "model1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78b341-3b64-42a5-8f05-4b2b85c7564a",
   "metadata": {},
   "source": [
    "## Another Example\n",
    "\n",
    "This time I am going use [Cancer Remission Dataset from UPenn](https://online.stat.psu.edu/onlinecourses/sites/stat501/files/data/leukemia_remission.txt):\n",
    "\n",
    "> The predictor variables are cellularity of the marrow clot section (CELL), smear differential percentage of blasts (SMEAR), percentage of absolute marrow leukemia cell infiltrate (INFIL), percentage labeling index of the bone marrow leukemia cells (LI), absolute number of blasts in the peripheral blood (BLAST), and the highest temperature prior to start of treatment (TEMP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "891289fd-dfc0-4e31-b69c-9b2c240b1a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REMISS</th>\n",
       "      <th>CELL</th>\n",
       "      <th>SMEAR</th>\n",
       "      <th>INFIL</th>\n",
       "      <th>LI</th>\n",
       "      <th>BLAST</th>\n",
       "      <th>TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    REMISS  CELL  SMEAR  INFIL   LI  BLAST  TEMP\n",
       "0        1  0.80   0.83   0.66  1.9   1.10  1.00\n",
       "1        1  0.90   0.36   0.32  1.4   0.74  0.99\n",
       "2        0  0.80   0.88   0.70  0.8   0.18  0.98\n",
       "3        0  1.00   0.87   0.87  0.7   1.05  0.99\n",
       "4        1  0.90   0.75   0.68  1.3   0.52  0.98\n",
       "5        0  1.00   0.65   0.65  0.6   0.52  0.98\n",
       "6        1  0.95   0.97   0.92  1.0   1.23  0.99\n",
       "7        0  0.95   0.87   0.83  1.9   1.35  1.02\n",
       "8        0  1.00   0.45   0.45  0.8   0.32  1.00\n",
       "9        0  0.95   0.36   0.34  0.5   0.00  1.04\n",
       "10       0  0.85   0.39   0.33  0.7   0.28  0.99\n",
       "11       0  0.70   0.76   0.53  1.2   0.15  0.98\n",
       "12       0  0.80   0.46   0.37  0.4   0.38  1.01\n",
       "13       0  0.20   0.39   0.08  0.8   0.11  0.99\n",
       "14       0  1.00   0.90   0.90  1.1   1.04  0.99\n",
       "15       1  1.00   0.84   0.84  1.9   2.06  1.02\n",
       "16       0  0.65   0.42   0.27  0.5   0.11  1.01\n",
       "17       0  1.00   0.75   0.75  1.0   1.32  1.00\n",
       "18       0  0.50   0.44   0.22  0.6   0.11  0.99\n",
       "19       1  1.00   0.63   0.63  1.1   1.07  0.99\n",
       "20       0  1.00   0.33   0.33  0.4   0.18  1.01\n",
       "21       0  0.90   0.93   0.84  0.6   1.59  1.02\n",
       "22       1  1.00   0.58   0.58  1.0   0.53  1.00\n",
       "23       0  0.95   0.32   0.30  1.6   0.89  0.99\n",
       "24       1  1.00   0.60   0.60  1.7   0.96  0.99\n",
       "25       1  1.00   0.69   0.69  0.9   0.40  0.99\n",
       "26       0  1.00   0.73   0.73  0.7   0.40  0.99"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = pd.read_csv('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/data/leukemia_remission.txt',sep='\\t')\n",
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21882492-799f-465e-858f-4140eecdbbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.399886\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>REMISS</td>      <th>  No. Observations:  </th>  <td>    27</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 24 Oct 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.3718</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>13:58:52</td>     <th>  Log-Likelihood:    </th> <td> -10.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -17.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.04670</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   64.2581</td> <td>   74.965</td> <td>    0.857</td> <td> 0.391</td> <td>  -82.670</td> <td>  211.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CELL</th>      <td>   30.8301</td> <td>   52.135</td> <td>    0.591</td> <td> 0.554</td> <td>  -71.353</td> <td>  133.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SMEAR</th>     <td>   24.6863</td> <td>   61.526</td> <td>    0.401</td> <td> 0.688</td> <td>  -95.903</td> <td>  145.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INFIL</th>     <td>  -24.9745</td> <td>   65.281</td> <td>   -0.383</td> <td> 0.702</td> <td> -152.923</td> <td>  102.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LI</th>        <td>    4.3605</td> <td>    2.658</td> <td>    1.641</td> <td> 0.101</td> <td>   -0.849</td> <td>    9.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BLAST</th>     <td>   -0.0115</td> <td>    2.266</td> <td>   -0.005</td> <td> 0.996</td> <td>   -4.453</td> <td>    4.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TEMP</th>      <td> -100.1734</td> <td>   77.753</td> <td>   -1.288</td> <td> 0.198</td> <td> -252.567</td> <td>   52.220</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.11 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 REMISS   No. Observations:                   27\n",
       "Model:                          Logit   Df Residuals:                       20\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Mon, 24 Oct 2022   Pseudo R-squ.:                  0.3718\n",
       "Time:                        13:58:52   Log-Likelihood:                -10.797\n",
       "converged:                       True   LL-Null:                       -17.186\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.04670\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     64.2581     74.965      0.857      0.391     -82.670     211.187\n",
       "CELL          30.8301     52.135      0.591      0.554     -71.353     133.013\n",
       "SMEAR         24.6863     61.526      0.401      0.688     -95.903     145.275\n",
       "INFIL        -24.9745     65.281     -0.383      0.702    -152.923     102.974\n",
       "LI             4.3605      2.658      1.641      0.101      -0.849       9.570\n",
       "BLAST         -0.0115      2.266     -0.005      0.996      -4.453       4.430\n",
       "TEMP        -100.1734     77.753     -1.288      0.198    -252.567      52.220\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.11 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = logit('REMISS ~ CELL + SMEAR + INFIL + LI + BLAST + TEMP', data=cancer).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "238bc72c-23c7-4f47-9872-432e73621f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X,y):\n",
    "    res = []\n",
    "    for i in range(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.5)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "        res.append(model.score(X_test,y_test))\n",
    "    tmp = sorted(res)[3:97]\n",
    "    return (min(tmp),max(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "349875ee-0ecb-43cb-b4dd-98f8db8d3cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.42857142857142855, 0.8571428571428571)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cancer[['CELL', 'SMEAR', 'INFIL', 'LI', 'BLAST', 'TEMP']]\n",
    "y = cancer['REMISS']\n",
    "\n",
    "bootstrap(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943cbfd2-a621-4a4f-9b04-efcf1bf0c2dd",
   "metadata": {},
   "source": [
    "## Another Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a9b2801-073d-4761-9659-1f139f53a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a511ebd-5268-4bc5-85cc-775083642181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1985-10-01</th>\n",
       "      <td>110.620003</td>\n",
       "      <td>112.160004</td>\n",
       "      <td>110.565002</td>\n",
       "      <td>112.139999</td>\n",
       "      <td>112.139999</td>\n",
       "      <td>153160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-10-02</th>\n",
       "      <td>112.139999</td>\n",
       "      <td>112.540001</td>\n",
       "      <td>110.779999</td>\n",
       "      <td>110.824997</td>\n",
       "      <td>110.824997</td>\n",
       "      <td>164640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-10-03</th>\n",
       "      <td>110.839996</td>\n",
       "      <td>111.184998</td>\n",
       "      <td>110.120003</td>\n",
       "      <td>110.870003</td>\n",
       "      <td>110.870003</td>\n",
       "      <td>147300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-10-04</th>\n",
       "      <td>110.870003</td>\n",
       "      <td>110.870003</td>\n",
       "      <td>109.855003</td>\n",
       "      <td>110.074997</td>\n",
       "      <td>110.074997</td>\n",
       "      <td>147900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-10-07</th>\n",
       "      <td>110.074997</td>\n",
       "      <td>110.135002</td>\n",
       "      <td>108.175003</td>\n",
       "      <td>108.199997</td>\n",
       "      <td>108.199997</td>\n",
       "      <td>128640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-17</th>\n",
       "      <td>10967.250000</td>\n",
       "      <td>11090.870117</td>\n",
       "      <td>10959.740234</td>\n",
       "      <td>11062.530273</td>\n",
       "      <td>11062.530273</td>\n",
       "      <td>4439190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-18</th>\n",
       "      <td>11368.759766</td>\n",
       "      <td>11374.379883</td>\n",
       "      <td>11035.799805</td>\n",
       "      <td>11147.740234</td>\n",
       "      <td>11147.740234</td>\n",
       "      <td>5047360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-19</th>\n",
       "      <td>11081.820312</td>\n",
       "      <td>11231.459961</td>\n",
       "      <td>11008.110352</td>\n",
       "      <td>11103.379883</td>\n",
       "      <td>11103.379883</td>\n",
       "      <td>4955090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-20</th>\n",
       "      <td>11081.219727</td>\n",
       "      <td>11279.809570</td>\n",
       "      <td>11001.280273</td>\n",
       "      <td>11046.709961</td>\n",
       "      <td>11046.709961</td>\n",
       "      <td>4628010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-21</th>\n",
       "      <td>10998.169922</td>\n",
       "      <td>11327.769531</td>\n",
       "      <td>10962.009766</td>\n",
       "      <td>11310.330078</td>\n",
       "      <td>11310.330078</td>\n",
       "      <td>4706440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9342 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close  \\\n",
       "Date                                                                 \n",
       "1985-10-01    110.620003    112.160004    110.565002    112.139999   \n",
       "1985-10-02    112.139999    112.540001    110.779999    110.824997   \n",
       "1985-10-03    110.839996    111.184998    110.120003    110.870003   \n",
       "1985-10-04    110.870003    110.870003    109.855003    110.074997   \n",
       "1985-10-07    110.074997    110.135002    108.175003    108.199997   \n",
       "...                  ...           ...           ...           ...   \n",
       "2022-10-17  10967.250000  11090.870117  10959.740234  11062.530273   \n",
       "2022-10-18  11368.759766  11374.379883  11035.799805  11147.740234   \n",
       "2022-10-19  11081.820312  11231.459961  11008.110352  11103.379883   \n",
       "2022-10-20  11081.219727  11279.809570  11001.280273  11046.709961   \n",
       "2022-10-21  10998.169922  11327.769531  10962.009766  11310.330078   \n",
       "\n",
       "               Adj Close      Volume  \n",
       "Date                                  \n",
       "1985-10-01    112.139999   153160000  \n",
       "1985-10-02    110.824997   164640000  \n",
       "1985-10-03    110.870003   147300000  \n",
       "1985-10-04    110.074997   147900000  \n",
       "1985-10-07    108.199997   128640000  \n",
       "...                  ...         ...  \n",
       "2022-10-17  11062.530273  4439190000  \n",
       "2022-10-18  11147.740234  5047360000  \n",
       "2022-10-19  11103.379883  4955090000  \n",
       "2022-10-20  11046.709961  4628010000  \n",
       "2022-10-21  11310.330078  4706440000  \n",
       "\n",
       "[9342 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = yf.download('NDX')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7fcb0290-5339-406b-ba20-c141db8d019a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5302932990794262, 0.5499892956540355)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['Open']\n",
    "y = df['Close'] > df['Open']\n",
    "       \n",
    "bootstrap(np.array(X).reshape((-1,1)),np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f4ce3ab-11f4-4169-a8cc-f222313efd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5470991222436309"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(np.array(X).reshape((-1,1)),y)\n",
    "model.score(np.array(X).reshape((-1,1)),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9451d801-5c11-4ae8-a8ad-a201fac7d31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1985-10-01             NaN\n",
       "1985-10-02             NaN\n",
       "1985-10-03      112.139999\n",
       "1985-10-04      110.824997\n",
       "1985-10-07      110.870003\n",
       "                  ...     \n",
       "2022-10-17    11033.580078\n",
       "2022-10-18    10692.059570\n",
       "2022-10-19    11062.530273\n",
       "2022-10-20    11147.740234\n",
       "2022-10-21    11103.379883\n",
       "Name: Close, Length: 9342, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87123570-de2d-4652-bec0-34c672501184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
